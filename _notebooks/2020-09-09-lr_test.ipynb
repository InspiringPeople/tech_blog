{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/AI_Master/Flex_NLP\n"
     ]
    }
   ],
   "source": [
    "# !pwd\n",
    "%cd /home/jovyan/AI_Master/Flex_NLP/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124848, 4)\n",
      "get_data function took 0.20489811897277832 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_num_labels\": 5,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "roberta-base\n",
      "CustomTransformerModel(\n",
      "  (transformer): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Learner split in 14 groups\n",
      "[Sequential(\n",
      "  (0): Embedding(50265, 768, padding_idx=1)\n",
      "  (1): Embedding(514, 768, padding_idx=1)\n",
      "  (2): Embedding(1, 768)\n",
      "  (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=5, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "# transformers\n",
    "import fastai\n",
    "import transformers\n",
    "from flex_transformer import *  \n",
    "from transformers import AdamW\n",
    "\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "\n",
    "from dataMgr import *\n",
    "\n",
    "\"\"\"# Model Configuration\n",
    "# model_class.pretrained_model_archive_map.keys()\n",
    "\n",
    "[bert]\n",
    "dict_keys(['bert-base-uncased', 'bert-large-uncased', 'bert-base-cased', \n",
    "'bert-large-cased', 'bert-base-multilingual-uncased', 'bert-base-multilingual-cased', \n",
    "'bert-base-chinese', 'bert-base-german-cased', 'bert-large-uncased-whole-word-masking', \n",
    "'bert-large-cased-whole-word-masking', 'bert-large-uncased-whole-word-masking-finetuned-squad', \n",
    "'bert-large-cased-whole-word-masking-finetuned-squad', 'bert-base-cased-finetuned-mrpc', \n",
    "'bert-base-german-dbmdz-cased', 'bert-base-german-dbmdz-uncased', 'bert-base-japanese', \n",
    "'bert-base-japanese-whole-word-masking', 'bert-base-japanese-char', 'bert-base-japanese-char-whole-word-masking', \n",
    "'bert-base-finnish-cased-v1', 'bert-base-finnish-uncased-v1', 'bert-base-dutch-cased'])\n",
    "\n",
    "[xlnet]\n",
    "dict_keys(['xlnet-base-cased', 'xlnet-large-cased'])\n",
    "\n",
    "[xlm]\n",
    "dict_keys(['xlm-mlm-en-2048', 'xlm-mlm-ende-1024', 'xlm-mlm-enfr-1024', 'xlm-mlm-enro-1024', \n",
    "'xlm-mlm-tlm-xnli15-1024', 'xlm-mlm-xnli15-1024', 'xlm-clm-enfr-1024', 'xlm-clm-ende-1024', \n",
    "'xlm-mlm-17-1280', 'xlm-mlm-100-1280'])\n",
    "\n",
    "[roberta]\n",
    "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', \n",
    "'roberta-base-openai-detector', 'roberta-large-openai-detector'])\n",
    "\n",
    "[distilbert]\n",
    "dict_keys(['distilbert-base-uncased', 'distilbert-base-uncased-distilled-squad', 'distilbert-base-cased', \n",
    "'distilbert-base-cased-distilled-squad', 'distilbert-base-german-cased', 'distilbert-base-multilingual-cased', \n",
    "'distilbert-base-uncased-finetuned-sst-2-english'])\n",
    "\"\"\"\n",
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig), # bert-base-uncased\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig), # xlnet-base-cased'\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig), # xlm-mlm-en-2048\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig), # distilroberta-base\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig) # distilbert-base-uncased\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def load_pretrained_model(model_type, pretrained_model_name):\n",
    "    model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
    "    config = config_class.from_pretrained(pretrained_model_name)\n",
    "    # config.num_labels = n_label\n",
    "    config.num_labels = 5\n",
    "\n",
    "    transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "    # transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
    "    custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)\n",
    "\n",
    "    return custom_transformer_model\n",
    "\n",
    "\n",
    "def fine_tuned_model(custom_transformer_model, databunch, model_path):\n",
    "\n",
    "    CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "    \n",
    "    learner = Learner(databunch, \n",
    "                custom_transformer_model, \n",
    "                opt_func = CustomAdamW, \n",
    "                metrics=[accuracy, error_rate])\n",
    "\n",
    "        \n",
    "    # For DistilBERT\n",
    "    list_layers = [learner.model.transformer.distilbert.embeddings,\n",
    "                learner.model.transformer.distilbert.transformer.layer[0],\n",
    "                learner.model.transformer.distilbert.transformer.layer[1],\n",
    "                learner.model.transformer.distilbert.transformer.layer[2],\n",
    "                learner.model.transformer.distilbert.transformer.layer[3],\n",
    "                learner.model.transformer.distilbert.transformer.layer[4],\n",
    "                learner.model.transformer.distilbert.transformer.layer[5],\n",
    "                learner.model.transformer.pre_classifier]\n",
    "\n",
    "    learner.split(list_layers)\n",
    "    num_groups = len(learner.layer_groups)\n",
    "    print('Learner split in',num_groups,'groups')\n",
    "    print(learner.layer_groups)\n",
    "\n",
    "\n",
    "    ## Train\n",
    "    learner.save('untrain')\n",
    "\n",
    "    seed_all(seed_val)\n",
    "    learner.load('untrain')\n",
    "\n",
    "    learner.freeze_to(-1)\n",
    "    learner.summary()\n",
    "\n",
    "    learner.lr_find()\n",
    "    # learner.recorder.plot(skip_end=10,suggestion=True)\n",
    "\n",
    "    learner.fit_one_cycle(1,max_lr=2e-03,moms=(0.8,0.7))\n",
    "    learner.save('first_cycle')\n",
    "\n",
    "    seed_all(seed_val)\n",
    "    learner.load('first_cycle')\n",
    "\n",
    "    learner.freeze_to(-2)\n",
    "    lr = 1e-5\n",
    "\n",
    "    learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "    learner.save('second_cycle')\n",
    "\n",
    "    seed_all(seed_val)\n",
    "    learner.load('second_cycle')\n",
    "\n",
    "    learner.freeze_to(-3)\n",
    "    learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))\n",
    "\n",
    "    learner.save('third_cycle')\n",
    "\n",
    "    learner.export(file = model_path)\n",
    "\n",
    "    return learner\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_model_info():\n",
    "    print(\"====================================== Model ======================================\")\n",
    "    print(\"분석하고자 하는 모델 정보를 입력해주세요.\")\n",
    "    # print(\"pre_trained 모델을 선택해주세요. \\n 1:distilbert 2:bert 3:roberta 4:.... (TBD)\")\n",
    "    model_i = 1\n",
    "    # print(\"분석 NLP Task를 선택해주세요. \\n 1: multi-label classification 2:ner 3:squad 4:..... (TBD)\")\n",
    "    task_i = 1\n",
    "    # print(\"Class Label 개수를 입력해주세요.\")\n",
    "    # n_label = int(input())\n",
    "    n_label = 5\n",
    "\n",
    "    model_info = [model_dict[model_i], task_dict[task_i], n_label]\n",
    "\n",
    "    print(\"=================== 입력해주신 Model 정보입니다 ===================\")\n",
    "    print(\"[분석 모델, NLP Task, Label 개수]\")\n",
    "    print(model_info)\n",
    "\n",
    "    return model_dict[model_i], task_dict[task_i], n_label\n",
    "\n",
    "def get_list_layers(learner, model_type):\n",
    "    if(model_type == \"distilbert\"):\n",
    "        # For DistilBERT\n",
    "        list_layers = [learner.model.transformer.distilbert.embeddings,\n",
    "                    learner.model.transformer.distilbert.transformer.layer[0],\n",
    "                    learner.model.transformer.distilbert.transformer.layer[1],\n",
    "                    learner.model.transformer.distilbert.transformer.layer[2],\n",
    "                    learner.model.transformer.distilbert.transformer.layer[3],\n",
    "                    learner.model.transformer.distilbert.transformer.layer[4],\n",
    "                    learner.model.transformer.distilbert.transformer.layer[5],\n",
    "                    learner.model.transformer.pre_classifier]\n",
    "    elif(model_type == \"bert\"):\n",
    "        # # For BERT\n",
    "        list_layers = [learner.model.transformer.bert.embeddings,\n",
    "                    learner.model.transformer.bert.encoder.layer[0],\n",
    "                    learner.model.transformer.bert.encoder.layer[1],\n",
    "                    learner.model.transformer.bert.encoder.layer[2],\n",
    "                    learner.model.transformer.bert.encoder.layer[3],\n",
    "                    learner.model.transformer.bert.encoder.layer[4],\n",
    "                    learner.model.transformer.bert.encoder.layer[5],\n",
    "                    learner.model.transformer.bert.encoder.layer[6],\n",
    "                    learner.model.transformer.bert.encoder.layer[7],\n",
    "                    learner.model.transformer.bert.encoder.layer[8],\n",
    "                    learner.model.transformer.bert.encoder.layer[9],\n",
    "                    learner.model.transformer.bert.encoder.layer[10],\n",
    "                    learner.model.transformer.bert.encoder.layer[11],\n",
    "                    learner.model.transformer.bert.pooler,\n",
    "                    learner.model.transformer.dropout,\n",
    "                    # learner.model.transformer.lin1,\n",
    "                    # learner.model.transformer.lin2,\n",
    "                    # learner.model.transformer.lin3,\n",
    "                    # learner.model.transformer.lin4,\n",
    "                    learner.model.transformer.classifier]\n",
    "    # elif(model_type == \"xlnet\"):\n",
    "        # # For XLNet\n",
    "        # list_layers = [learner.model.transformer.xlnet.embeddings,\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[0],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[1],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[2],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[3],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[4],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[5],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[6],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[7],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[8],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[9],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[10],\n",
    "        #             learner.model.transformer.xlnet.transformer.layer[11],\n",
    "        #             learner.model.transformer.pre_classifier]\n",
    "    elif(model_type == \"roberta\"):\n",
    "        # For Roberta\n",
    "        list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "                learner.model.transformer.roberta.encoder.layer[0],\n",
    "                learner.model.transformer.roberta.encoder.layer[1],\n",
    "                learner.model.transformer.roberta.encoder.layer[2],\n",
    "                learner.model.transformer.roberta.encoder.layer[3],\n",
    "                learner.model.transformer.roberta.encoder.layer[4],\n",
    "                learner.model.transformer.roberta.encoder.layer[5],\n",
    "                learner.model.transformer.roberta.encoder.layer[6],\n",
    "                learner.model.transformer.roberta.encoder.layer[7],\n",
    "                learner.model.transformer.roberta.encoder.layer[8],\n",
    "                learner.model.transformer.roberta.encoder.layer[9],\n",
    "                learner.model.transformer.roberta.encoder.layer[10],\n",
    "                learner.model.transformer.roberta.encoder.layer[11],\n",
    "                learner.model.transformer.roberta.pooler]\n",
    "\n",
    "    elif(model_type == \"distilroberta\"): # distilroberta\n",
    "            # For Roberta\n",
    "        list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "                learner.model.transformer.roberta.encoder.layer[0],\n",
    "                learner.model.transformer.roberta.encoder.layer[1],\n",
    "                learner.model.transformer.roberta.encoder.layer[2],\n",
    "                learner.model.transformer.roberta.encoder.layer[3],\n",
    "                learner.model.transformer.roberta.encoder.layer[4],\n",
    "                learner.model.transformer.roberta.encoder.layer[5],\n",
    "                learner.model.transformer.roberta.pooler]\n",
    "\n",
    "    return list_layers\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_name = 'movie_en_5label'\n",
    "    model_type = 'roberta'\n",
    "    pretrained_model_name = 'roberta-base'\n",
    "\n",
    "    # data_name = sys.argv[1]\n",
    "    # model_type = sys.argv[2]\n",
    "    # pretrained_model_name = sys.argv[3]\n",
    "    finetuned_model_name = './models/' + data_name + '_' + pretrained_model_name + '.pkl'\n",
    "        \n",
    "    train, test, n_label, doc_name, label_name = get_data(data_name)\n",
    "    model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
    "\n",
    "    transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "    transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "    fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])\n",
    "\n",
    "    # Custom Processor\n",
    "    transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "    numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "    tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "    transformer_processor = [tokenize_processor, numericalize_processor]\n",
    "\n",
    "\n",
    "    # Setting up DatBunch\n",
    "    pad_first = bool(model_type in ['xlnet'])\n",
    "    pad_idx = transformer_tokenizer.pad_token_id\n",
    "\n",
    "    databunch = (TextList.from_df(train, cols=doc_name, processor=transformer_processor)\n",
    "                .split_by_rand_pct(0.1,seed=seed_val)\n",
    "                .label_from_df(cols= label_name)\n",
    "                # .add_test(test)\n",
    "                .databunch())\n",
    "\n",
    "    config = config_class.from_pretrained(pretrained_model_name)\n",
    "    config.num_labels = n_label # get n_label\n",
    "    config.use_bfloat16 = False # use_fp16\n",
    "    print(config)\n",
    "\n",
    "    print(pretrained_model_name)\n",
    "\n",
    "    # For Bert\n",
    "    # transformer_model = BertForSequenceClassification.from_pretrained(pretrained_model_name, config = config)\n",
    "    transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "\n",
    "    custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)\n",
    "\n",
    "    # learner = fine_tuned_model(custom_transformer_model, train, './wm_ref_tv.pkl')\n",
    "\n",
    "    CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "    \n",
    "    learner = Learner(databunch, \n",
    "                custom_transformer_model, \n",
    "                opt_func = CustomAdamW, \n",
    "                metrics=[accuracy, error_rate])\n",
    "\n",
    "    print(learner.model)\n",
    "    \n",
    "    list_layers = get_list_layers(learner, model_type)\n",
    "\n",
    "    learner.split(list_layers)\n",
    "    num_groups = len(learner.layer_groups)\n",
    "    print('Learner split in',num_groups,'groups')\n",
    "    print(learner.layer_groups)\n",
    "\n",
    "\n",
    "    ## Train\n",
    "    learner.save('untrain')\n",
    "\n",
    "    seed_all(seed_val)\n",
    "    learner.load('untrain')\n",
    "\n",
    "    learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [75, 768]            38,603,520 False     \n",
       "______________________________________________________________________\n",
       "Embedding            [75, 768]            394,752    False     \n",
       "______________________________________________________________________\n",
       "Embedding            [75, 768]            768        False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 75, 75]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [75, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [75, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [75, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Tanh                 [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [5]                  3,845      True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 125,240,069\n",
       "Total trainable params: 1,185,029\n",
       "Total non-trainable params: 124,055,040\n",
       "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='71' class='' max='1755', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      4.05% [71/1755 00:07<02:47 5.2353]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 1.91E-04\n",
      "Min loss divided by 10: 1.74E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end=10, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.199539</td>\n",
       "      <td>1.233606</td>\n",
       "      <td>0.510574</td>\n",
       "      <td>0.489426</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (112364 items)\n",
       "x: TextList\n",
       "<s> Ġunintentionally Ġ- RR B - </s>,<s> Ġwill Ġneed Ġall Ġthe Ġluck Ġthey Ġcan Ġmuster Ġjust Ġfiguring Ġout Ġwho Ġ' s Ġwho Ġin Ġthis Ġpret entious Ġmess </s>,<s> Ġsomewhere Ġbetween ĠS ling ĠBlade Ġand ĠSouth Ġof ĠHeaven Ġ, ĠWest Ġof ĠHell </s>,<s> Ġreminds Ġat Ġevery Ġturn Ġof ĠElizabeth ĠBerk ley Ġ' s Ġflo pping Ġdolphin - g asm </s>,<s> Ġthe ĠMag i </s>\n",
       "y: CategoryList\n",
       "2,0,2,1,2\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (12484 items)\n",
       "x: TextList\n",
       "<s> Ġk idd ie Ġentertainment </s>,<s> Ġfinally Ġmakes ĠSex ĠWith ĠStr angers Ġ, Ġwhich Ġopens Ġtoday Ġin Ġthe ĠNew ĠYork Ġmetropolitan Ġarea Ġ, Ġso Ġdist ast eful </s>,<s> Ġmuch Ġas Ġthey Ġlove Ġthemselves </s>,<s> Ġupdate Ġher Ġbeloved Ġgenre </s>,<s> Ġbeautiful Ġwomen </s>\n",
       "y: CategoryList\n",
       "2,0,2,2,2\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=CustomTransformerModel(\n",
       "  (transformer): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'transformers.optimization.AdamW'>, correct_bias=False), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f8dfd183158>, <function error_rate at 0x7f8dfd183378>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Embedding(50265, 768, padding_idx=1)\n",
       "  (1): Embedding(514, 768, padding_idx=1)\n",
       "  (2): Embedding(1, 768)\n",
       "  (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (4): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "), Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=768, out_features=5, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learner.fit_one_cycle(1,max_lr=2e-03,moms=(0.8,0.7))\n",
    "learner.fit_one_cycle(1,max_lr=slice(1e-05, 1e-03))\n",
    "learner.save('first_cycle')\n",
    "\n",
    "seed_all(seed_val)\n",
    "learner.load('first_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='77' class='' max='1755', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      4.39% [77/1755 00:07<02:50 3.9110]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 9.12E-07\n",
      "Min loss divided by 10: 1.32E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(skip_end=10, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.116296</td>\n",
       "      <td>1.071130</td>\n",
       "      <td>0.568728</td>\n",
       "      <td>0.431272</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.freeze_to(-2)\n",
    "# lr = 1e-5\n",
    "learner.fit_one_cycle(1, max_lr=slice(1e-06, 1e-04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "learner.callbacks.append(ShowGraph(learner))\n",
    "print(learner.model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
